from __future__ import absolute_import, division, print_function, unicode_literals
#from skimage import io, transform
import glob
import os
import sys
import numpy as np
import time
import xlrd
from openpyxl import load_workbook
from openpyxl import Workbook
from openpyxl.writer.excel import ExcelWriter
import cv2
# import xlwt
import tensorflow as tf
import pandas
from keras import losses
# from tensorflow.keras import layers
import tensorflow.keras as keras
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from scipy import interp
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.metrics import recall_score
from sklearn.model_selection import cross_validate, train_test_split
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
#from sklearn.cross_validation import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import recall_score,accuracy_score
from sklearn.metrics import precision_score,f1_score
from sklearn.metrics import roc_curve
from sklearn.metrics import auc
from sklearn.model_selection import cross_val_predict
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt
from keras.utils.np_utils import to_categorical
###
#import tensorflow.keras as keras
import matplotlib.pyplot as plt
from keras import regularizers
###
sys.path.append("..")
#print('the path of common is {}'.format(sys.path))
import COMMON.draw_roc as draw_roc
from AI.models.resnet import resnet34
from AI.models.ception import Xception
from AI.models.models import LeNet
from AI.models.models import CNN3
from AI.models.models import AlexNet
from AI.models.models import AlexNet1

'''
  Add in 20200826
'''
from AI.models.models import VGG16
from AI.models.models import VGG19
from AI.models.models import InceptionV3

'''
    Add ImageNet-based transfer learning in 20200903
    Selected the best model according to RandomizedSearchCv in 20201105
    name: xisx
'''
import itertools
from sklearn.model_selection import RandomizedSearchCV

'''
   add from AI.models.models import CNN_features_model
   name: ben

'''
from AI.models import CNN_features_model 


def create_model(model_types, image_sizes_list,label_types, parameters_list=None, activation='relu', init_mode='uniform', optimizer='Adam', metrics_type='accuracy', compile_loss=losses.categorical_crossentropy):
    print("model_types:", model_types)
    model = eval(model_types)(image_sizes_list, label_types, parameters_list, activation, init_mode)

    # def get_lr_metric(optimizer):
    #     def lr(y_true, y_pred):
    #         return optimizer.lr
    #
    #     return lr
    #
    # lr_metric = get_lr_metric(optimizer)

    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[metrics_type])
    model.summary()

    return model


def train_by_all(n_splits, save_model_address, model_types, train_images, train_labels,test_images,test_labels, image_sizes_list, label_types, parameters_list, activation='relu', init_mode='uniform', optimizer='Adam', metrics_type='accuracy',epochs =2, batch_size=2,roc_address="roc.pdf",roc_title="ROC curve"):
    parameters_list1 = parameters_list.split(",")
    i = 0
    print("-------------------------in the beginning of train_by_all_trainning_set:")
    tprs = []
    aucs = []
    mean_fpr = np.linspace(0, 1, 100)
    if True:
        # 建立模型，并对训练集进行测试，求出预测得分
        # 划分训练集和测试集
        X_train, X_test = np.array(train_images), np.array(test_images)
        Y_train, Y_test = np.array(train_labels), np.array(test_labels)

        Y_train = to_categorical(Y_train, num_classes=None)
        Y_test = Y_train
        # 建立模型(模型已经定义)
        print("|||||||||||||||before eval:")
        model = create_model(model_types, image_sizes_list,label_types, parameters_list1[0], activation, init_mode, optimizer, metrics_type)

        # 训练模型
        print("|||||||||||||||before fit:")
        model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs)
        probas_ = model.predict(X_test, batch_size=batch_size)
        #now change to common draw_roc_curve(Y_test[:,1], probas_[:, 1],roc_address,roc_title=roc_title)
        auc_title = ""
        draw_roc.draw_roc_curve(Y_test[:,1], probas_[:, 1],roc_address,auc_title,roc_title=roc_title)

    model.save(save_model_address)  # creates a HDF5 file 'my_model.h5'
    # step7
    del model  # deletes the existing model
    print("-------------after del model")

def cross_validation_one_time(n_splits, save_model_address, model_types, train_images, train_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title, **extra):
#def cross_validation_one_time(n_splits, save_model_address, model_types, train_images, train_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, roc_address, roc_title):
    if n_splits == 1:
        TF_split_list_2 = [(np.array( list(range(len(train_labels))) ), np.array( list(range(len(train_labels))) ))]
    else:
        KF = KFold(n_splits=n_splits, shuffle=True, random_state=7)
        TF_split_list_2 = KF.split(train_images)
    i = 0

    tprs = []
    aucs = []
    mean_fpr = np.linspace(0, 1, 100)

    print("label_types:",label_types)
    model = KerasClassifier(build_fn=create_model,model_types=model_types, image_sizes_list=image_sizes_list, label_types=label_types, parameters_list=parameters_list, activation=activation, init_mode=init_mode, optimizer=optimizer, metrics_type=metrics_type)
    print("roc_address: ",roc_address)
    pdf = PdfPages(roc_address)         #先创建一个pdf文件
    plt.figure
    for train_index, test_index in TF_split_list_2: ##KF.split(train_images):
        # 建立模型，并对训练集进行测试，求出预测得分
        # 划分训练集和测试集
        X_train, X_test = np.array(train_images)[train_index], np.array(train_images)[test_index]
        Y_train, Y_test = np.array(train_labels)[train_index], np.array(train_labels)[test_index]

        print("Y_train:",Y_train)


        early_stopping = keras.callbacks.EarlyStopping(monitor='loss',min_delta=0.001, patience=5, verbose=2)
        model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs, verbose=2,  shuffle=False, callbacks=[early_stopping])
        probas_ = model.predict(X_test, batch_size=batch_size)
        ##################
        # Compute ROC curve and area the curve
        fpr, tpr, thresholds = roc_curve(Y_test[:,1], probas_)
        tprs.append(interp(mean_fpr, fpr, tpr))
        tprs[-1][0] = 0.0
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)
        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))
        i += 1

    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    std_auc = np.std(aucs)
    plt.plot(mean_fpr, mean_tpr, color='b',
         label=r'Mean ROC (AUC = %0.2f $\pm$ %0.2f)' % (mean_auc, std_auc),
         lw=2, alpha=.8)

    std_tpr = np.std(tprs, axis=0)
    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,
                 label=r'$\pm$ 1 std. dev.')

    plt.xlim([-0.05, 1.05])
    plt.ylim([-0.05, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(roc_title)
    plt.legend(loc="lower right")
    plt.savefig(roc_address)
    plt.show()
    pdf.savefig()                            #将图片保存在pdf文件中
    plt.close()
    pdf.close()
    print("aucs:",aucs)
    print("mean_auc",mean_auc, " ",std_auc)

    # step7
    print("-------------after del model")
    return mean_auc,model

def cross_validation_select_parameters_by_hands(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title, **extra):
    print("parameters_list:",parameters_list)
    parameters_dic = eval(parameters_list)
    all_parameters_name = sorted(parameters_dic)
    combination_parameters = itertools.product(*(parameters_dic[name] for name in all_parameters_name))
    y_scores_max = -1
    times_best = 0
    X_train = np.array(train_images)
    Y_train = np.array(train_labels)
    Y_train = to_categorical(Y_train, 2)
    print("-------------------------- roc_address is :", roc_address)
    times = 0

    for parameters_list_1 in combination_parameters:
        times += 1
        roc_address1 = roc_address + "_" +str(times) + ".pdf"
        #y_scores_mean,model = cross_validation_one_time(n_splits, save_model_address, model_types, X_train, Y_train, image_sizes_list, label_types, para, activation, init_mode, optimizer, metrics_type, roc_address1, roc_title)
        y_scores_mean,model = cross_validation_one_time(n_splits, save_model_address, model_types, X_train, Y_train, image_sizes_list, label_types, parameters_list_1, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address1, roc_title, **extra)
        if y_scores_mean > y_scores_max:
            combination_parameters_best = parameters_list_1
            y_scores_max = y_scores_mean
        print("y_scores_mean:", y_scores_mean, "  parameters_list_best:", combination_parameters_best)
    #### construst model by best hyperparameters
    if times == 1:
        #y_scores_mean,model = cross_validation_one_time(1, save_model_address, model_types, X_train, Y_train, image_sizes_list, label_types, combination_parameters_best, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title)
        y_scores_mean,model = cross_validation_one_time(1, save_model_address, model_types, X_train, Y_train, image_sizes_list, label_types, combination_parameters_best, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title, **extra)
    model.model.save(save_model_address)  # creates a HDF5 file 'my_model.h5'
    print(" model has been saved to ", save_model_address)


def Keras_Classifier(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation='relu', init_mode='uniform', optimizer='Adam', metrics_type='accuracy', cross_valadation_code=1, epochs=2, batch_size=2, roc_address="roc.pdf", roc_title="ROC curve"):
    print("begin of keras_classifier: image_sizes_list:",image_sizes_list, "type:", image_sizes_list)

    parameters_list1 = parameters_list.split(",")
    model = create_model(model_types=model_types, image_sizes_list=image_sizes_list, label_types=label_types, parameters_list=parameters_list1[0], activation=activation, init_mode=init_mode, optimizer=optimizer, metrics_type=metrics_type)
    kfold = KFold(n_splits=int(n_splits), shuffle=True, random_state=5000)
    for train, test in kfold.split(train_images):
        print("train:",train, "test",test)
    if False:
        scoring = ['precision_macro','recall_macro']
        scores = cross_validate(model, train_images, train_labels,scoring=scoring,cv=kfold,return_train_score=False)
        sorted(scores.keys())
        #['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']
        print(scores['test_recall_macro'])
    elif False:
        if False:
            # sklearn.model_selection.cross_val_score Returns  scoresarray of float, shape=(len(list(cv)),)  Array of scores of the estimator for each run of the cross validation.
            y_pre = cross_val_score(model, train_images, train_labels, cv=kfold)
        else:
            y_pre = cross_val_predict(model, train_images, train_labels, cv=kfold)
        auc_title = ""
        draw_roc.draw_roc_curve(train_labels, y_pre, roc_address, auc_title, roc_title=roc_title)

    else:
        '''
        y_pre = cross_val_score(model, train_images, train_labels, cv=kfold)
        print("y_pre is ", y_pre)

        # predictions = pandas.Series(y_pre)
        # print("pre:",y_pre,"predictions:",predictions)
        auc_title = ""
        draw_roc.draw_roc_curve(train_labels, y_pre, roc_address, auc_title, roc_title=roc_title)
        '''
        pass


    #X_train, X_test = np.array(train_images), np.array(test_images)
    #Y_train, Y_test = np.array(train_labels), np.array(test_labels)
    #Y_train = to_categorical(Y_train, num_classes=None)
    #Y_test = Y_train
    # 建立模型(模型已经定义)
    #model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test), epochs=epochs)
    #model.fit(train_images, train_labels, batch_size=2, validation_data=(train_images, train_labels), epochs=2)
    model.save(save_model_address)
    print(" this  is the end")


def algorithm_pipeline(X_train_data, y_train_data, X_test_data, y_test_data,
                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',
                       do_probabilities=False, search_type=0):
    print("-------------------------param_grid is:", type(param_grid))

    if search_type == 0:
        gs = GridSearchCV(estimator=model,
                          param_grid=param_grid,
                          cv=cv,
                          verbose=2,
                          # n_jobs=-1,
                          scoring=scoring_fit)

    if search_type == 1:
        gs = RandomizedSearchCV(estimator=model,
                                param_distributions=param_grid,
                                cv=cv,
                                verbose=2,
                                n_jobs=1,
                                scoring=scoring_fit)

    Early_sp = tf.keras.callbacks.EarlyStopping(
        monitor='accuracy',
        patience=3,
        mode='auto',
        verbose=1
    )

    fitted_model = gs.fit(X_train_data, y_train_data, callbacks=[Early_sp])  # , callbacks=[Early_sp]

    best_model = gs.best_estimator_
    if do_probabilities:
      pred = fitted_model.predict_proba(X_test_data)
    else:
      pred = fitted_model.predict(X_test_data)
    print("pred:",pred)

    return best_model, pred, fitted_model


def cross_validation_select_parameters_by_GridSearchCV(n_splits, save_model_address,model_types,train_images,train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list,activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title):
    '''

    :param parameters_list:
         For example: {
                        'times': [2],
                        'epochs': [100,150,200],
                        'batch_size': [32, 128],
                        'optimizer': ['Adam', 'Nadam'],
                        'dropout_rate': [0.2, 0.3]
                        'activation': ['relu', 'elu']
                        'init_mode':['uniform', 'lecun_uniform', 'normal']
                     }
    :return: best model based on the parameters_list information
    '''
    print("begin of crosss_validation_select_parameters_by_GridSearchCV: ")
    y_scores_max = -1
    times_best = 0
    X_train = np.array(train_images)
    Y_train = np.array(train_labels)

    ##### split data start
    #seed = 7 #重现随机生成的训练
    #test_size = 0.33 #33%测试，67%训练
    #test_size = 0.50 #33%测试，67%训练
    #X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels, test_size=test_size, random_state=seed)
    ##### split data end

    parameters_dic = eval(parameters_list)
    param_grid = parameters_dic

    #init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']
    #init_mode = ['uniform','lecun_uniform','normal']
    #param_grid = dict(init_mode=init_mode)
    #model = XGBClassifier()
    #now model = KerasClassifier(build_fn = build_cnn, activation = 'relu', dropout_rate = 0.2, optimizer = 'Adam', fs1 = 5, times = times, init_mode='uniform', verbose=1)

    model = KerasClassifier(build_fn=create_model,model_types=model_types, image_sizes_list=image_sizes_list, label_types=label_types, parameters_list=parameters_list)
    #model = create_model(model_types=model_types, image_sizes_list=image_sizes_list, label_types=label_types, parameters_list=parameters_list)
    best_model, pred, fitted_model = algorithm_pipeline(train_images, train_labels, test_images, test_labels, model, param_grid, cv=n_splits, scoring_fit='neg_log_loss',do_probabilities=True)
    auc_title = ""
    draw_roc.draw_roc_curve(test_labels, pred[:,1], roc_address, auc_title, roc_title=roc_title)
    best_model.model.save(save_model_address)


def cross_validation_select_parameters_by_RandomizedSearchCV(n_splits, save_model_address, model_types,
                                                             train_images, train_labels, test_images, test_labels,
                                                             image_sizes_list, label_types, parameters_list, roc_address, roc_title):
    y_scores_max = -1
    times_best = 0
    X_train = np.array(train_images)
    Y_train = np.array(train_labels)

    parameters_dic = eval(parameters_list)
    param_grid = parameters_dic

    model = KerasClassifier(build_fn=create_model, model_types=model_types, image_sizes_list=image_sizes_list,
                            label_types=label_types, parameters_list=parameters_list)
    best_estimator, pred, fitted_model = algorithm_pipeline(train_images, train_labels, test_images, test_labels,
                                                            model, param_grid=param_grid, cv=n_splits,
                                                            scoring_fit='neg_log_loss', do_probabilities=True, search_type=1)

    auc_title = ""
    draw_roc.draw_roc_curve(test_labels, pred[:, 1], roc_address, auc_title, roc_title=roc_title)
    best_model.model.save(save_model_address)


def model_train(n_splits, save_model_address, model_types, train_images, train_labels,test_images, test_labels, image_sizes_list, label_types, parameters_list, activation='relu', init_mode='uniform', optimizer='Adam', metrics_type='accuracy', epochs=2, batch_size=2, cross_valadation_code=1, roc_address="roc.pdf", roc_title="ROC curve"):
    tf.config.threading.set_inter_op_parallelism_threads = 50
    # 只使用一个线程
    os.environ["OMP_NUM_THREADS"] = "1"
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    if cross_valadation_code == 1:
        pass
    elif cross_valadation_code == 2:  #### cross_validation 1 time on  cross_val_predict
        Keras_Classifier(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, cross_valadation_code, epochs, batch_size, roc_address, roc_title)
    elif cross_valadation_code == 3:
        cross_validation_select_parameters_by_hands(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title)
    elif cross_valadation_code == 4:  ### cross_validation on hyperparameters  on GridSearchCV
        cross_validation_select_parameters_by_GridSearchCV(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title)
    elif cross_valadation_code == 5:
        cross_validation_select_parameters_by_RandomizedSearchCV(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, roc_address, roc_title)
    elif cross_valadation_code == 0:
        train_by_all(n_splits, save_model_address, model_types, train_images, train_labels, test_images, test_labels, image_sizes_list, label_types, parameters_list, activation, init_mode, optimizer, metrics_type, epochs, batch_size, roc_address, roc_title)


def model_test_multi(save_model_address, model_name, test_images, test_labels,roc_address,roc_title="ROC curve"):
    restored_model = tf.keras.models.load_model(save_model_address)

    test_images = np.array(test_images)
    test_labels = np.array(test_labels)
    test_labels = to_categorical(test_labels, num_classes=None)
    # step9
    loss, acc = restored_model.evaluate(test_images, test_labels)
    print("Restored model, accuracy:{:5.2f}%".format(100 * acc))
    # pred = restored_model.predict(test_images[:2])
    #print('predict:', pred )
    # https://blog.csdn.net/wwwlyj123321/article/details/94291992
    # 利用model.predict获取测试集的预测值
    y_pred = restored_model.predict(test_images, batch_size=1)
    #draw_roc_curve(test_labels[:,1], y_pred[:,1], roc_address, roc_title)
    auc_title = ""
    ####下面的语句需要检查其中test_labels是否为二维数据。
    draw_roc.draw_roc_curve(test_labels[:,1], y_pred[:, 1],roc_address,auc_title,roc_title=roc_title)
    return test_labels[:,1], y_pred[:, 1]

def model_test_single(save_model_address, test_image):
    restored_model = tf.keras.models.load_model(save_model_address)
    test_image = np.array(test_image)
    # step9
    # pred = restored_model.predict(test_images[:2])
    #print('predict:', pred )
    # https://blog.csdn.net/wwwlyj123321/article/details/94291992
    # 利用model.predict获取测试集的预测值
    y_pred = restored_model.predict(test_image, batch_size=1)
    return y_pred





